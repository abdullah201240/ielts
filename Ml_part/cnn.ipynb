{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2b15b5-6561-41b9-a014-e4bea3cadfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97711049-b725-435a-8603-2b926effd8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ielts_writing_dataset.csv')\n",
    "\n",
    "\n",
    "questions = data['Question'].astype(str)\n",
    "answers = data['Essay'].astype(str)\n",
    "marks = data['Overall'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a9c2fb-d5ae-42ce-9eac-e5d845c1676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000  \n",
    "max_sequence_length = 100  \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "\n",
    "question_sequences = tokenizer.texts_to_sequences(questions)\n",
    "answer_sequences = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "X = pad_sequences(question_sequences, maxlen=max_sequence_length)\n",
    "X_ans = pad_sequences(answer_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13de069-4e49-487f-abcc-1391a7e245a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_ans_train, X_ans_test, y_train, y_test = train_test_split(X, X_ans, marks, test_size=0.2, random_state=42)\n",
    "\n",
    "embedding_dim = 100  \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9eba8d-933f-418e-9ab8-ba9283325fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_input = Sequential()\n",
    "question_input.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))\n",
    "question_input.add(Conv1D(128, 5, activation='relu'))\n",
    "question_input.add(GlobalMaxPooling1D())\n",
    "\n",
    "answer_input = Sequential()\n",
    "answer_input.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))\n",
    "answer_input.add(Conv1D(128, 5, activation='relu'))\n",
    "answer_input.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4dd0f9-38df-4bf6-89a2-a44c960a7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 1s 20ms/step - loss: 33.0332 - val_loss: 17.9004\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 7.2606 - val_loss: 1.7425\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 2.3364 - val_loss: 1.2562\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.3074 - val_loss: 1.0775\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1.0803 - val_loss: 0.9633\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.9511 - val_loss: 0.9137\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.8486 - val_loss: 0.8836\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.7701 - val_loss: 0.8516\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.6816 - val_loss: 0.8232\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.6088 - val_loss: 0.8019\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.5303 - val_loss: 0.7887\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4690 - val_loss: 0.7878\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3970 - val_loss: 0.7603\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.3355 - val_loss: 0.7652\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.2727 - val_loss: 0.7372\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.2117 - val_loss: 0.7256\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1632 - val_loss: 0.7178\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.1266 - val_loss: 0.7097\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0936 - val_loss: 0.7051\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0686 - val_loss: 0.6965\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0524 - val_loss: 0.7065\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0419 - val_loss: 0.7007\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 0.0328 - val_loss: 0.6974\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error (MAE): 0.70\n",
      "Mean Squared Error (MSE): 0.83\n"
     ]
    }
   ],
   "source": [
    "concatenated = Concatenate()([question_input.output, answer_input.output])\n",
    "out = Dense(1, activation='linear')(concatenated)\n",
    "\n",
    "model = Model(inputs=[question_input.input, answer_input.input], outputs=out)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit([X_train, X_ans_train], y_train, epochs=30, batch_size=64,validation_split=0.1,callbacks=[early_stopping])\n",
    "\n",
    "y_pred = model.predict([X_test, X_ans_test])\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab5d57f-d5ef-4273-9d18-47782b765297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Predicted Mark: 4.46\n"
     ]
    }
   ],
   "source": [
    "new_question = [\"How does photosynthesis work?\"]\n",
    "new_answer = [\"Photosynthesis is the process by which plants convert light energy into chemical energy.\"]\n",
    "\n",
    "new_question_seq = tokenizer.texts_to_sequences(new_question)\n",
    "new_answer_seq = tokenizer.texts_to_sequences(new_answer)\n",
    "\n",
    "new_question_padded = pad_sequences(new_question_seq, maxlen=max_sequence_length)\n",
    "new_answer_padded = pad_sequences(new_answer_seq, maxlen=max_sequence_length)\n",
    "\n",
    "predicted_mark = model.predict([new_question_padded, new_answer_padded])[0][0]\n",
    "print(f\"Predicted Mark: {predicted_mark:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74c3b9c-5c13-440c-b7c1-a71dc7b1b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdullahalsakib/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('ieltsscore.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81932507-7c51-40c0-84cb-1f467a0aec67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
